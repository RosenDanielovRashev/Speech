import streamlit as st
import re
from collections import Counter
import nltk
from textblob import TextBlob

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–∞–Ω–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ç–∞
st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞ –ò–∑—Ä–µ—á–µ–Ω–∏—è",
    page_icon="üî§",
    layout="wide"
)

# CSS –∑–∞ –ø–æ-–¥–æ–±—ä—Ä –≤–∏–∑—É–∞–ª–µ–Ω –≤–∏–¥
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .stats-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #1f77b4;
    }
    .sentence-box {
        background-color: white;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 8px;
        border-left: 4px solid #ff6b6b;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .sentence-number {
        background-color: #1f77b4;
        color: white;
        padding: 0.3rem 0.8rem;
        border-radius: 15px;
        font-weight: bold;
        font-size: 0.9rem;
    }
    .real-time-badge {
        background-color: #ff4b4b;
        color: white;
        padding: 0.2rem 0.8rem;
        border-radius: 15px;
        font-size: 0.8rem;
        animation: pulse 2s infinite;
    }
    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.7; }
        100% { opacity: 1; }
    }
    .word-count-badge {
        background-color: #28a745;
        color: white;
        padding: 0.2rem 0.6rem;
        border-radius: 12px;
        font-size: 0.8rem;
    }
</style>
""", unsafe_allow_html=True)

def split_into_sentences(text):
    """–†–∞–∑–¥–µ–ª—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è —Å –ø–æ–¥–æ–±—Ä–µ–Ω –∞–ª–≥–æ—Ä–∏—Ç—ä–º"""
    if not text.strip():
        return []
    
    # –ü–∞—Ç—ä—Ä–Ω –∑–∞ —Ä–∞–∑–¥–µ–ª—è–Ω–µ –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è (–ø–æ–¥–æ–±—Ä–µ–Ω)
    sentence_endings = r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|\!|\‚Ä¶)\s'
    
    # –†–∞–∑–¥–µ–ª—è–Ω–µ –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è
    sentences = re.split(sentence_endings, text)
    
    # –§–∏–ª—Ç—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –ø—Ä–∞–∑–Ω–∏ –∏–∑—Ä–µ—á–µ–Ω–∏—è –∏ –ø—Ä–µ–º–∞—Ö–≤–∞–Ω–µ –Ω–∞ –≤–æ–¥–µ—â–∏/–∑–∞–≤—ä—Ä—à–≤–∞—â–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∏
    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]
    
    return sentences

def analyze_sentence(sentence, sentence_num):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–∞ –æ—Ç–¥–µ–ª–Ω–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ"""
    words = re.findall(r'\b\w+\b', sentence.lower())
    characters = len(sentence)
    characters_no_spaces = len(sentence.replace(" ", ""))
    
    return {
        'number': sentence_num,
        'text': sentence,
        'words': len(words),
        'characters': characters,
        'characters_no_spaces': characters_no_spaces,
        'word_list': words
    }

def analyze_text_in_real_time(text):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–∞ —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ–∞–ª–Ω–æ –≤—Ä–µ–º–µ —Å —Ñ–æ–∫—É—Å –≤—ä—Ä—Ö—É –∏–∑—Ä–µ—á–µ–Ω–∏—è—Ç–∞"""
    if not text.strip():
        return None
    
    # –†–∞–∑–¥–µ–ª—è–Ω–µ –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è
    sentences = split_into_sentences(text)
    
    # –ê–Ω–∞–ª–∏–∑ –Ω–∞ –≤—Å—è–∫–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ
    analyzed_sentences = [analyze_sentence(sent, i+1) for i, sent in enumerate(sentences)]
    
    # –û–±—â–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    all_words = []
    for sent in analyzed_sentences:
        all_words.extend(sent['word_list'])
    
    total_words = len(all_words)
    total_characters = len(text)
    total_characters_no_spaces = len(text.replace(" ", ""))
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è—Ç–∞
    sentence_stats = {
        'count': len(sentences),
        'avg_words_per_sentence': total_words / len(sentences) if sentences else 0,
        'avg_chars_per_sentence': total_characters / len(sentences) if sentences else 0,
        'shortest_sentence': min(sentences, key=len) if sentences else "",
        'longest_sentence': max(sentences, key=len) if sentences else ""
    }
    
    # –î–æ–ø—ä–ª–Ω–∏—Ç–µ–ª–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    unique_words = len(set(all_words))
    avg_word_length = sum(len(word) for word in all_words) / total_words if total_words > 0 else 0
    reading_time = total_words / 200  # 200 –¥—É–º–∏ –≤ –º–∏–Ω—É—Ç–∞
    
    # –ù–∞–π-—á–µ—Å—Ç–æ —Å—Ä–µ—â–∞–Ω–∏ –¥—É–º–∏
    word_freq = Counter(all_words)
    common_words = word_freq.most_common(15)
    
    return {
        'sentences': analyzed_sentences,
        'sentence_stats': sentence_stats,
        'total_words': total_words,
        'total_characters': total_characters,
        'total_characters_no_spaces': total_characters_no_spaces,
        'unique_words': unique_words,
        'avg_word_length': avg_word_length,
        'reading_time': reading_time,
        'common_words': common_words,
        'all_words': all_words
    }

def display_sentence_analysis(sentences):
    """–ü–æ–∫–∞–∑–≤–∞ –¥–µ—Ç–∞–π–ª–µ–Ω –∞–Ω–∞–ª–∏–∑ –Ω–∞ –≤—Å—è–∫–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ"""
    if not sentences:
        return
    
    st.subheader(f"üìë –ê–Ω–∞–ª–∏–∑ –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è—Ç–∞ ({len(sentences)} –æ–±—â–æ)")
    
    for sentence_data in sentences:
        with st.container():
            col1, col2 = st.columns([4, 1])
            
            with col1:
                st.markdown(f'<div class="sentence-box">', unsafe_allow_html=True)
                st.markdown(f'**–ò–∑—Ä–µ—á–µ–Ω–∏–µ {sentence_data["number"]}:**')
                st.write(sentence_data['text'])
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div style="margin-top: 2rem;">', unsafe_allow_html=True)
                st.markdown(f'<span class="word-count-badge">{sentence_data["words"]} –¥—É–º–∏</span>', unsafe_allow_html=True)
                st.write(f"üî§ {sentence_data['characters']} —Å–∏–º–≤–æ–ª–∞")
                st.markdown('</div>', unsafe_allow_html=True)
        
        st.write("")  # –î–æ–±–∞–≤—è–º–µ –º–∞–ª–∫–æ —Ä–∞–∑—Å—Ç–æ—è–Ω–∏–µ

def main():
    # –ó–∞–≥–ª–∞–≤–∏–µ
    st.markdown("""
    <div style="display: flex; align-items: center; justify-content: center; gap: 1rem;">
        <h1 class="main-header">üî§ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞ –ò–∑—Ä–µ—á–µ–Ω–∏—è</h1>
        <span class="real-time-badge">–†–ï–ê–õ–ù–û –í–†–ï–ú–ï</span>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # –°–∞–π–¥–±–∞—Ä –∑–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑")
        
        show_detailed_sentences = st.checkbox("–ü–æ–∫–∞–∂–∏ –¥–µ—Ç–∞–π–ª–µ–Ω –∞–Ω–∞–ª–∏–∑ –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è—Ç–∞", value=True)
        show_sentence_stats = st.checkbox("–ü–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è—Ç–∞", value=True)
        show_word_frequency = st.checkbox("–ü–æ–∫–∞–∂–∏ —á–µ—Å—Ç–æ—Ç–∞ –Ω–∞ –¥—É–º–∏", value=True)
        
        st.markdown("---")
        st.header("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        st.write("""
        **–ù–æ–≤–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
        - üìë –†–∞–∑–¥–µ–ª—è–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è
        - üîç –ê–Ω–∞–ª–∏–∑ –Ω–∞ –≤—Å—è–∫–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ –ø–æ–æ—Ç–¥–µ–ª–Ω–æ
        - üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –¥—ä–ª–∂–∏–Ω–∞ –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è
        - ‚ö° –ú–æ–º–µ–Ω—Ç–∞–ª–µ–Ω –∞–Ω–∞–ª–∏–∑ –≤ —Ä–µ–∞–ª–Ω–æ –≤—Ä–µ–º–µ
        """)
    
    # –û—Å–Ω–æ–≤–Ω–∞ –æ–±–ª–∞—Å—Ç
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # –¢–µ–∫—Å—Ç–æ–≤–∞ –æ–±–ª–∞—Å—Ç
        st.subheader("üéØ –í—ä–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –∑–∞ –∞–Ω–∞–ª–∏–∑")
        
        # –ü—Ä–∏–º–µ—Ä–µ–Ω —Ç–µ–∫—Å—Ç –∑–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è
        sample_text = """–¢–æ–≤–∞ –µ –ø—ä—Ä–≤–æ—Ç–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ. –¢–æ —Å—ä–¥—ä—Ä–∂–∞ –Ω—è–∫–æ–ª–∫–æ –¥—É–º–∏!
        –í—Ç–æ—Ä–æ—Ç–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ –µ –º–∞–ª–∫–æ –ø–æ-–¥—ä–ª–≥–æ –∏ –ø–æ–∫–∞–∑–≤–∞ –∫–∞–∫ —Ä–∞–±–æ—Ç–∏ —Ä–∞–∑–¥–µ–ª—è–Ω–µ—Ç–æ.
        –¢—Ä–µ—Ç–æ –ª–∏ –µ —Ç–æ–≤–∞? –ß–µ—Ç–≤—ä—Ä—Ç–æ—Ç–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ –∑–∞–≤—ä—Ä—à–≤–∞ —Å —É–¥–∏–≤–∏—Ç–µ–ª–µ–Ω –∑–Ω–∞–∫!"""
        
        text = st.text_area(
            "–ü–∏—à–µ—Ç–µ —Ç—É–∫:",
            height=300,
            placeholder="–ó–∞–ø–æ—á–Ω–µ—Ç–µ –¥–∞ –ø–∏—à–µ—Ç–µ... –¢–µ–∫—Å—Ç—ä—Ç —â–µ –±—ä–¥–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Ä–∞–∑–¥–µ–ª–µ–Ω –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è –∑–∞ –∞–Ω–∞–ª–∏–∑.",
            key="real_time_input",
            label_visibility="collapsed",
            value=sample_text
        )
        
        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç
        if text:
            sentences = split_into_sentences(text)
            st.success(f"‚úÖ –†–∞–∑–ø–æ–∑–Ω–∞—Ç–∏ {len(sentences)} –∏–∑—Ä–µ—á–µ–Ω–∏—è –≤ —Ä–µ–∞–ª–Ω–æ –≤—Ä–µ–º–µ!")
    
    with col2:
        st.subheader("üìä –û–±—â–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        
        # –ê–Ω–∞–ª–∏–∑ –≤ —Ä–µ–∞–ª–Ω–æ –≤—Ä–µ–º–µ
        if text.strip():
            analysis = analyze_text_in_real_time(text)
            
            if analysis:
                # –û—Å–Ω–æ–≤–Ω–∏ –º–µ—Ç—Ä–∏–∫–∏
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("üìù –û–±—â–æ –¥—É–º–∏", analysis['total_words'])
                    st.metric("üìë –ò–∑—Ä–µ—á–µ–Ω–∏—è", analysis['sentence_stats']['count'])
                    st.metric("üî§ –£–Ω–∏–∫–∞–ª–Ω–∏ –¥—É–º–∏", analysis['unique_words'])
                
                with col2:
                    st.metric("üìä –°–∏–º–≤–æ–ª–∏", analysis['total_characters'])
                    st.metric("‚è±Ô∏è –í—Ä–µ–º–µ –∑–∞ —á–µ—Ç–µ–Ω–µ", f"{analysis['reading_time']:.1f} –º–∏–Ω")
                    st.metric("üìè –°—Ä. –¥—ä–ª–∂–∏–Ω–∞ –Ω–∞ –¥—É–º–∞", f"{analysis['avg_word_length']:.1f}")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è—Ç–∞
                if show_sentence_stats and analysis['sentence_stats']['count'] > 0:
                    with st.expander("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è—Ç–∞", expanded=True):
                        st.markdown('<div class="stats-box">', unsafe_allow_html=True)
                        
                        stats = analysis['sentence_stats']
                        st.write(f"**–°—Ä–µ–¥–Ω–æ –¥—É–º–∏ –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏–µ:** {stats['avg_words_per_sentence']:.1f}")
                        st.write(f"**–°—Ä–µ–¥–Ω–æ —Å–∏–º–≤–æ–ª–∏ –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏–µ:** {stats['avg_chars_per_sentence']:.1f}")
                        
                        if stats['count'] > 1:
                            st.write("---")
                            st.write("**–ù–∞–π-–∫—Ä–∞—Ç–∫–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ:**")
                            st.info(stats['shortest_sentence'])
                            
                            st.write("**–ù–∞–π-–¥—ä–ª–≥–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ:**")
                            st.info(stats['longest_sentence'])
                        
                        st.markdown('</div>', unsafe_allow_html=True)
                
                # –ß–µ—Å—Ç–æ—Ç–∞ –Ω–∞ –¥—É–º–∏
                if show_word_frequency and analysis['common_words']:
                    with st.expander("üî§ –ß–µ—Å—Ç–æ —Å—Ä–µ—â–∞–Ω–∏ –¥—É–º–∏"):
                        for word, count in analysis['common_words'][:10]:
                            percentage = (count / analysis['total_words']) * 100
                            st.write(f"`{word}`: {count} –ø—ä—Ç–∏ ({percentage:.1f}%)")
        
        else:
            st.info("üí° –ó–∞–ø–æ—á–Ω–µ—Ç–µ –¥–∞ –ø–∏—à–µ—Ç–µ –≤ –ª—è–≤–∞—Ç–∞ –∫–æ–ª–æ–Ω–∞...")
            st.write("""
            **–©–µ –≤–∏–¥–∏—Ç–µ:**
            - –ë—Ä–æ–π –∏–∑—Ä–µ—á–µ–Ω–∏—è
            - –ê–Ω–∞–ª–∏–∑ –Ω–∞ –≤—Å—è–∫–æ –∏–∑—Ä–µ—á–µ–Ω–∏–µ
            - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –¥—ä–ª–∂–∏–Ω–∞
            - –ß–µ—Å—Ç–æ —Å—Ä–µ—â–∞–Ω–∏ –¥—É–º–∏
            """)
    
    # –î–µ—Ç–∞–π–ª–µ–Ω –∞–Ω–∞–ª–∏–∑ –Ω–∞ –∏–∑—Ä–µ—á–µ–Ω–∏—è—Ç–∞
    if text.strip() and show_detailed_sentences:
        st.markdown("---")
        analysis = analyze_text_in_real_time(text)
        if analysis and analysis['sentences']:
            display_sentence_analysis(analysis['sentences'])

if __name__ == "__main__":
    main()
